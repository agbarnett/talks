---
title: Evidence of statistical 'hacking' in clinical prediction models
author: Adrian Barnett
date: "2 August 2023"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: dracula
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "https://platform.twitter.com/widgets.js"
    seal: false 
---

```{r setup, include=FALSE}
# see https://github.com/rstudio-education/arm-workshop-rsc2019/blob/master/static/slides/xaringan.Rmd
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, error=FALSE, comment='', dpi=400, fig.align='center')
options(htmltools.dir.version = FALSE)
#xaringanExtra::use_xaringan_extra(c("tile_view", "animate_css", "tachyons"))
library(tidyverse)
library(dplyr)
library(ggplot2)
library(knitr)
library(flextable)
library(fontawesome) # from github: https://github.com/rstudio/fontawesome
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

layout: true
  
---
name: xaringan-title
class: inverse, left, middle

.pull-left[

# .center[Evidence of statistical 'hacking' in clinical prediction models]

### .center[Adrian Barnett (QUT), Nicole White (QUT), Rex Parsons (QUT), Gary Collins (Oxford)]

### .center[2 August 2023]

[`r fa(name = "twitter")` @aidybarnett](http://twitter.com/aidybarnett)  

[`r fa(name = "github")` @agbarnett](http://github.com/agbarnett)  

[`r fa(name = "blog")` Median Watch](https://medianwatch.netlify.app)

[`r fa(name = "paper-plane")` a.barnett@qut.edu.au](mailto:a.barnett@qut.edu.au)

]


.pull-right[

![](https://media.giphy.com/media/YFigaZwm2EiFG/giphy.gif)

(from giphy)

]

---
background-image: url(figures/AcknowledgementTraditionalOwners.jpg)
background-size: cover



---
class: inverse, center, middle

<!--- what is a clinical prediction model --->

```{r, out.width='80%'}
knitr::include_graphics(path='figures/cardiac-troponin-ed-pathway.png')
```

---
## Common statistics

### Sensitivity = True positive / (True positive + False negative)

### Specificity = True negative / (True negative + False positive)

---
## Area under curve (AUC)

```{r, out.width = "50%"}
# text
text1 = data.frame(x=0.25, number = 1, text = 'Best') %>% mutate(y = x^(1/3))
text2 = data.frame(x=0.4, number = 2, text = 'Better') %>%  mutate(y = x^(1/2))
text3 = data.frame(x=0.5, number = 3, text = 'Random') %>% mutate(y = x)
text4 = data.frame(x=0.05, number = 4, y = 1, text = 'Perfect')
text = bind_rows(text1, text2, text3, text4)
#
line1 = data.frame(x = seq(1,0,-0.01)) %>%
  mutate(y = x^(1/3), number = 1)
line2 = data.frame(x = seq(1,0,-0.01)) %>%
  mutate(y = x^(1/2), number = 2)
line3 = data.frame(x = seq(1,0,-0.01)) %>%
  mutate(y = x, number = 3)
lines = bind_rows(line1, line2, line3)
ggplot(data = lines, aes(x=x, y=y, col=factor(number)))+
  geom_line(size=1.4)+
  scale_color_manual(NULL, values=c('darkseagreen3','orange','grey','black'))+
  geom_label(data = text, aes(x=x, y=y, label=text, col=factor(number)), size=7)+
  xlab('1 - specificity (False positive proportion)')+
  ylab('sensitivity (True positive proportion)')+
  theme_bw()+
  theme(text = element_text(size=20),
        legend.position = 'none',
        panel.grid.minor = element_blank())

```

---
## Increasing prevalence over time

```{r, out.width='71%'}
# from 5_summary.Rmd
knitr::include_graphics(path='figures/trend_for_slide.jpg')
```

##### Results from _PubMed_

---
class:inverse
## Previous concerns about clinical prediction models:

* ### Small sample sizes
* ### Inappropriate exclusions
* ### Lack of validation
* ### Poor reporting
* ### Inflated estimates of performance

--

### A review of prediction models for COVID-19 found only 7 of the 606 published models were potentially useful for practice (DOI: [10.1136/bmj.m1328](https://www.bmj.com/content/369/bmj.m1328))

---
.left-column[
# Small sample size
]

.right-column[

```{r, out.width='69%'}
# from https://pubmed.ncbi.nlm.nih.gov/22577751/
knitr::include_graphics(path='figures/pubmed_22577751.png')
```

]


---
class: inverse
# Spin

* ### "Further, the FPDS biomarker achieved state-of-the-art performance on the mild cognitive impairment (MCI) to DAT conversion prediction task with an AUC of 0.81, 0.80, 0.77 for the 2, 3, 5 years to conversion windows respectively." [PMID29876266](https://pubmed.ncbi.nlm.nih.gov/29876266/)

--

* ### "the result of the ROC Curve area is 0.801, which suggests that our prediction model has good predictive ability and strong stability, so we believe that the model can be generally applied to other groups of people'' [PMID29876266](https://pubmed.ncbi.nlm.nih.gov/29876266/)

--

* ### "Through the SMOTE-Bagged Tree algorithm, the AUC value obtained by our model is 0.80, which proves that our model has a proper prediction ability, and can be used for early breast cancer patients." [PMID31041192](https://pubmed.ncbi.nlm.nih.gov/31041192/)

---
class:inverse
# Likely results for 1,000 patients

### AUC = sensitivity = specificity = 0.80

### Pre-test probability = 0.05

```{r}
# see 99_play_numbers.R in AUC folder
tab = data.frame(Test = c('Positive','Negative','Positive','Negative'), outcome = c('Diseased','Diseased','Well','Well'), n = c(40,10,190,760))
tab = tidyr::pivot_wider(tab, values_from = 'n', names_from = 'outcome')
ftab = flextable(tab) %>%
  theme_box %>%
  fontsize(size = 22, part = 'all')%>%
  color(color = 'gold', part='all')
ftab
```

---
# Mass testing

* ### 75% of US men older than 50 years have been screened with prostate-specific antigen (PSA) for prostate cancer

* ### Large follow-up study of over 8,500 men

* ### AUC for test to discriminate any prostate cancer versus no cancer was 0.678 (95% confidence interval 0.666 to 0.689) 

[DOI: 10.1001/jama.294.1.66](https://jamanetwork.com/journals/jama/fullarticle/201171)

---
class: center, middle
### Sloppy practice

```{r, out.width='70%'}
# from main paper of https://pubmed.ncbi.nlm.nih.gov/31041192/
knitr::include_graphics(path='figures/frontiers.jpg')
```

---
## Qualitative descriptors for AUC cut-offs

### "An AUC value of more than 0.9 was considered outstanding and 0.8-0.9 as excellent." [PMID35537614](https://pubmed.ncbi.nlm.nih.gov/35537614/)

--

### "An AUC of 0.5 suggests no discrimination, 0.7-0.8 is considered acceptable, more than 0.8-0.9 is considered excellent, and more than 0.9 is considered outstanding.'' [PMID34793687](https://pubmed.ncbi.nlm.nih.gov/34793687/)

--

### "Generally speaking, when the AUC value of a model is at the range of 0.7-0.8, the prediction ability of the model is superior. When the AUC value is at the range of 0.8-0.9, the prediction ability of the model is very good.'' [PMID31041192](https://pubmed.ncbi.nlm.nih.gov/31041192/)

---
class:center,middle

![](https://media.giphy.com/media/RH8Cwr2yWNsmuPCBiO/giphy.gif)

(from Visutrainment on giphy)

---
class:inverse
## P-value hacking at the 0.05 threshold

```{r, out.width='64%'}
# from U:\Research\Projects\ihbi\aushsi\aushsi_barnetta\meta.research\text.mining\outside.confidence.intervals\figures\4_plot_z.R
knitr::include_graphics(path='figures/Z_plot_slide.png')
```

DOI: [10.1111/stan.12241](https://onlinelibrary.wiley.com/doi/full/10.1111/stan.12241)

---
## Cronbach's alpha hacking

```{r, out.width='61%'}
knitr::include_graphics(path='figures/cronbach.png')
```

DOI: [10.31234/osf.io/dm8xn](https://europepmc.org/article/ppr/ppr612639)


---
class: inverse, centre, middle

# Hypothesis: We will see hacking in clinical prediction models using the AUC values


---
## How to hack a prediction model

Pick best model after ...

* Adding or removing predictors

* Remove "difficult" patients or centres

* Running different methods (e.g., logistic regression, classification tree)

* Trying different random test-validation splits


---
# Validation

### Algorithm versus 300 manually checked abstracts with MESH term "Area under the curve"

* ### **No AUC**: algorithm correct =  179 / 192 (93%)

* ### **With AUC**: algorithm correct =  100 / 102 (98%)

--

### Easier general sample of 100 manually checked abstracts without MESH term restriction

* ### **No AUC**: algorithm correct =  100 / 100

* ### **With AUC**: algorithm correct =  99 / 100

---
# Validation

```{r}
knitr::include_graphics(path='figures/combined_validation.jpg')
```


---

.left-column[
# Challenging presentations
]

.right-column[

```{r, out.width='72%'}
knitr::include_graphics(path='figures/pubmed_35645149.png')
```
]

---
# Validating specific AUC values

```{r}
knitr::include_graphics(path='figures/validate_specific.jpg')
```


---
# Methods

* ### Group results into bins of (lower, upper] and draw histogram

* ### Lower thresholds of 0.50, 0.51, ..., 0.99; upper threshold +0.01

--

* ### Excluded AUCs of "0.5", "0.6", "0.7", "0.8", "0.9" - create spikes in the histogram due to rounding, also often used as thresholds 

---
# Expected histogram without hacking

```{r, out.width='40%'}
x = seq(0.45,1.2,0.001)
y = dnorm(x, mean=0.72, sd=0.13)
data = data.frame(x=x, y=y)
pplot = ggplot(data = data, aes(x=x, y=y))+
  geom_line(size=1)+
  geom_vline(lty=1, xintercept=1)+
  xlab('AUC')+
  ylab('Frequency')+
  theme_minimal()+
  scale_x_continuous(breaks = seq(0.5, 1.2, 0.1))+
  scale_y_continuous(breaks = NULL)+
  theme(panel.grid.minor = element_blank(),
        text = element_text(size=20))
pplot
```

---
# Expected histogram with hacking

```{r, out.width='40%'}
x = seq(0.45,1.2,0.001)
y = dnorm(x, mean=0.72, sd=0.13)
z = y + 0.22*cos(x*2*pi/0.1)
data = data.frame(x=x, y=y, z=z)
pplot = ggplot(data, aes(x=x, y=y))+
  geom_line(size=1.2)+
  geom_line(data = data, aes(x=x, y=z), col='red', size=1.2)+
  geom_vline(lty=1, xintercept=1)+
  xlab('AUC')+
  ylab('Frequency')+
  theme_minimal()+
  scale_x_continuous(breaks = seq(0.5, 1.2, 0.1))+
  scale_y_continuous(breaks = NULL)+
  theme(panel.grid.minor = element_blank(),
        text = element_text(size=20))
pplot
```

--

### Smoothed the histogram using a natural spline with 4 degrees of freedom

---
.left-column[
# Included abstracts
]

.right-column[
```{r, out.width='53%'}
knitr::include_graphics(path='figures/consort.flow.jpg')
```
]

---
# Histogram and residuals

```{r, out.width='78%'}
knitr::include_graphics(path='figures/histogram_residuals_slide.jpg')
```

---
## AUC values from the lower and upper confidence limits

```{r, out.width='78%'}
knitr::include_graphics(path='figures/histogram_residuals_intervals_slide.jpg')
```

---
# Results just for _PLOS ONE_

```{r, out.width='74%'}
knitr::include_graphics(path='figures/histogram_just_plos_slide.jpg')
```

---
# Conclusions

### Hacking has occurred relatively often

* Survey of Australian researchers reported many were aware of instances where colleagues had made up data (10%), altered data (8%), selectively excluded data (27%), or trialed iterative statistical analysis until finding a model that yielded a "significant” result (45%) [DOI: 10.1038/s41562-023-01621-w](https://www.nature.com/articles/s41562-023-01621-w)

--

### Likely some publication bias too

--

### Also uncovered lots of poor practice

### Pre-print here: [https://osf.io/ap6t4](https://osf.io/ap6t4)

---
class: inverse
# Actions needed

* ### Automated peer review checks [DOI: 10.1186/s13104-022-06080-6](https://bmcresnotes.biomedcentral.com/articles/10.1186/s13104-022-06080-6)

--

* ### Courses aimed at non-statisticians

--

* ### Funders should stop funding clinical prediction models unless there is an experienced statistician on the team


---
background-image: url(figures/aimos_conference_slide2.jpg)
